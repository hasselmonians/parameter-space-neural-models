
@article{poiraziArithmeticSubthresholdSynaptic2003,
  langid = {english},
  title = {Arithmetic of {{Subthreshold Synaptic Summation}} in a {{Model CA1 Pyramidal Cell}}},
  volume = {37},
  issn = {0896-6273},
  url = {https://www.cell.com/neuron/abstract/S0896-6273(03)00148-X},
  doi = {10.1016/S0896-6273(03)00148-X},
  number = {6},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  urldate = {2019-11-25},
  date = {2003-03-27},
  pages = {977-987},
  author = {Poirazi, Panayiota and Brannon, Terrence and Mel, Bartlett W.},
  file = {/home/alec/Zotero/storage/CIS982G2/Poirazi et al. - 2003 - Arithmetic of Subthreshold Synaptic Summation in a.pdf;/home/alec/Zotero/storage/YIIAC7GN/S0896-6273(03)00148-X.html},
  eprinttype = {pmid},
  eprint = {12670426}
}

@article{destexheIonicMechanismsUnderlying1996,
  langid = {english},
  title = {Ionic Mechanisms Underlying Synchronized Oscillations and Propagating Waves in a Model of Ferret Thalamic Slices},
  volume = {76},
  issn = {0022-3077},
  doi = {10.1152/jn.1996.76.3.2049},
  abstract = {1. A network model of thalamocortical (TC) and thalamic reticular (RE) neurons was developed based on electrophysiological measurements in ferret thalamic slices. Single-compartment TC and RE cells included voltage- and calcium-sensitive currents described by Hodgkin-Huxley type of kinetics. Synaptic currents were modeled by kinetic models of alpha-amino-3-hydroxy-5-methyl-4-isoxazolepropionic acid (AMPA), gamma-aminobutyric acid-A (GABAA) and GABAB receptors. 2. The model reproduced successfully the characteristics of spindle and slow bicuculline-induced oscillations observed in vitro. The characteristics of these two types of oscillations depended on both the intrinsic properties of TC and RE cells and their pattern of interconnectivity. 3. The oscillations were organized by the reciprocal recruitment between TC and RE cells, due to their manual connectivity and bursting properties. TC cells elicited AMPA-mediated excitatory postsynaptic potentials (EPSPs) in RE cells, whereas RE cells elicited a mixture of GABAA and GABAB inhibitory postsynaptic potentials (IPSPs) in TC cells. Because of the presence of a T current, sufficiently strong EPSPs could elicit a burst in RE cells, and TC cells could generate a rebound burst following GABAergic IPSPs. Under these conditions, interaction between the TC and RE cells produced sustained oscillations. 4. In the absence of spontaneous oscillation in any cell, the TC-RE network remained quiescent. Spindle oscillations with a frequency of 9-11 Hz could be initiated by stimulation of either TC or RE neurons. A few spontaneously oscillating TC neurons recruited the entire network model into a "waxing-and waning" oscillation. These "initiator" cells could be an extremely small proportion of TC cells. 5. In intracellular recordings, TC cells display a reduced ability for burst firing after a sequence of bursts. The "waning" phase of spindles was reproduced in the network model by assuming an activity-dependent upregulation of Ih operating via a calcium-binding protein in TC cells, as shown previously in a two-cell model. 6. Following the global suppression of GABAA inhibition, the disinhibited RE cells produced prolonged burst discharges that elicited strong GABAB-mediated currents in TC cells. The enhancement of slow IPSPs in TC cells was also due to cooperativity in the activation of GABAB-mediated current. These slow IPSPs recruited TC and RE cells into slower waxing-and-waning oscillations (3-4 HZ) that were even more highly synchronized. 7. Local axonal arborization of the TC to RE and RE to TC projections allowed oscillations to propagate through the network. An oscillation starting at a single focus induced a propagating wavefront as more cells were recruited progressively. The waning of the oscillation also propagated due to upregulation of Ih in TC cells, leading to waves of spindle activity as observed in experiments. 8. The spatiotemporal properties of propagating waves in the model were highly dependent on the intrinsic properties of TC cells. The spatial pattern of spiking activity was markedly different for spindles compared with bicuculline-induced oscillations and depended on the rebound burst behavior of TC cells. The upregulation of Ih produced a refractory period so that colliding spindle waves merged into a single oscillation and extinguished. Finally, reducing the Ih conductance led to sustained oscillations. 9. Two key properties of cells in the thalamic network may account for the initiation, propagation, and termination of spindle oscillations, the activity-dependent upregulation of Ih in TC cells, and the localized axonal projections between TC and RE cells. In addition, the model predicts that a nonlinear stimulus dependency of GABAB responses accounts for the genesis of prolonged synchronized discharges following block of GABAA receptors.},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J. Neurophysiol.},
  date = {1996-09},
  pages = {2049-2070},
  keywords = {Synapses,Animals,Thalamus,Ion Channels,Kinetics,Models; Neurological,Calcium Channels,Membrane Potentials,Potassium Channels,In Vitro Techniques,Neural Networks (Computer),Calcium,Electrophysiology,Axons,Bicuculline,Ferrets,GABA Antagonists,Recruitment; Neurophysiological,Refractory Period; Electrophysiological,Reticular Formation,Up-Regulation},
  author = {Destexhe, A. and Bal, T. and McCormick, D. A. and Sejnowski, T. J.},
  file = {/home/alec/Zotero/storage/7KGW4I9I/Destexhe et al. - 1996 - Ionic mechanisms underlying synchronized oscillati.pdf;/home/alec/Zotero/storage/HIIGUUDP/Destexhe et al. - 1996 - Ionic mechanisms underlying synchronized oscillati.pdf},
  ids = {destexheIonicMechanismsUnderlying1996a},
  eprinttype = {pmid},
  eprint = {8890314}
}

@article{yuanStructuralInsightsDynamic2019,
  langid = {english},
  title = {Structural {{Insights Into}} the {{Dynamic Evolution}} of {{Neuronal Networks}} as {{Synaptic Density Decreases}}},
  volume = {13},
  issn = {1662-4548},
  doi = {10.3389/fnins.2019.00892},
  abstract = {The human brain is thought to be an extremely complex but efficient computing engine, processing vast amounts of information from a changing world. The decline in the synaptic density of neuronal networks is one of the most important characteristics of brain development, which is closely related to synaptic pruning, synaptic growth, synaptic plasticity, and energy metabolism. However, because of technical limitations in observing large-scale neuronal networks dynamically connected through synapses, how neuronal networks are organized and evolve as their synaptic density declines remains unclear. Here, by establishing a biologically reasonable neuronal network model, we show that despite a decline in the synaptic density, the connectivity, and efficiency of neuronal networks can be improved. Importantly, by analyzing the degree distribution, we also find that both the scale-free characteristic of neuronal networks and the emergence of hub neurons rely on the spatial distance between neurons. These findings may promote our understanding of neuronal networks in the brain and have guiding significance for the design of neuronal network models.},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front Neurosci},
  date = {2019},
  pages = {892},
  keywords = {evolving network model,network connectivity,network efficiency,scale-free network,synaptic density},
  author = {Yuan, Ye and Liu, Jian and Zhao, Peng and Xing, Fu and Huo, Hong and Fang, Tao},
  file = {/home/alec/Zotero/storage/2MXJLZDS/Yuan et al. - 2019 - Structural Insights Into the Dynamic Evolution of .pdf},
  eprinttype = {pmid},
  eprint = {31507365},
  pmcid = {PMC6714520}
}

@article{izhikevichWhichModelUse2004,
  langid = {english},
  title = {Which Model to Use for Cortical Spiking Neurons?},
  volume = {15},
  issn = {1045-9227},
  doi = {10.1109/TNN.2004.832719},
  abstract = {We discuss the biological plausibility and computational efficiency of some of the most useful models of spiking and bursting neurons. We compare their applicability to large-scale simulations of cortical neural networks.},
  number = {5},
  journaltitle = {IEEE transactions on neural networks},
  shortjournal = {IEEE Trans Neural Netw},
  date = {2004-09},
  pages = {1063-1070},
  keywords = {Neurons,Synapses,Animals,Synaptic Transmission,Action Potentials,Humans,Neural Pathways,Models; Neurological,Nerve Net,Cerebral Cortex,Reaction Time,Nonlinear Dynamics},
  author = {Izhikevich, Eugene M.},
  eprinttype = {pmid},
  eprint = {15484883}
}

@article{destexheModelSpindleRhythmicity1994,
  langid = {english},
  title = {A Model of Spindle Rhythmicity in the Isolated Thalamic Reticular Nucleus},
  volume = {72},
  issn = {0022-3077},
  doi = {10.1152/jn.1994.72.2.803},
  abstract = {1. The oscillatory properties of the isolated reticular (RE) thalamus were modeled with the use of compartmental models of RE cells. Hodgkin-Huxley type kinetic models of ionic channels were derived from voltage- and current-clamp data from RE cells. Interactions between interconnected RE cells were simulated with the use of a kinetic model of gamma-aminobutyric acid (GABA) inhibitory synapses. 2. The intrinsic bursting properties of RE cells in the model were due to the presence of a low-threshold Ca2+ current and two Ca(2+)-activated currents. The properties of these model RE cells were compared with RE neurons recorded intracellularly in vivo in cats. 3. Model RE cells densely interconnected with GABAA synapses produced synchronous oscillations at a frequency close to that of spindles (7-14 Hz). Networks of RE neurons organized in a two-dimensional array with only proximal connectivity also exhibited synchronized oscillations in the spindle range. In addition, the proximally connected network showed periods of high and low synchronicity, giving rise to waxing and waning oscillations in the population of RE cells. 4. The spatiotemporal behavior of the network was investigated during waxing and waning oscillations. The waxing and waning emerged as an alternation between periods of desynchronized and synchronized activity, corresponding to periods of irregular and coherent spatial activity. During synchronized periods, the network displayed propagating coherent waves of synchronous activity that had a tendency to form spirals. 5. Networks of model RE neurons fully connected through GABAB synapses exhibited perfectly synchronous oscillations at lower frequencies (0.5-1 Hz), but two-dimensional networks with proximal GABAB connectivity failed to synchronize. 6. These simulations demonstrate that networks of model neurons that include the main intrinsic currents found in RE cells can generate waxing and waning oscillatory activity similar to the spindle rhythmicity observed in the isolated RE nucleus in vivo. The model reveals the interplay between the intrinsic rhythmic properties of RE cells and the fast synaptic interactions in organizing synchronized rhythmicity.},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J. Neurophysiol.},
  date = {1994-08},
  pages = {803-818},
  keywords = {Synapses,Animals,Synaptic Transmission,Ion Channels,Calcium Channels,Membrane Potentials,Potassium Channels,Nerve Net,Cats,Cerebral Cortex,Electroencephalography,Neural Networks (Computer),Neural Inhibition,Sleep Stages,Afferent Pathways,gamma-Aminobutyric Acid,Receptors; GABA-B,Thalamic Nuclei},
  author = {Destexhe, A. and Contreras, D. and Sejnowski, T. J. and Steriade, M.},
  file = {/home/alec/Zotero/storage/CNBQW5VE/Destexhe et al. - 1994 - A model of spindle rhythmicity in the isolated tha.pdf;/home/alec/Zotero/storage/MWREW6E3/Destexhe et al. - 1994 - A model of spindle rhythmicity in the isolated tha.pdf},
  ids = {destexheModelSpindleRhythmicity1994a},
  eprinttype = {pmid},
  eprint = {7527077}
}

@article{hasselmoDynamicsLearningRecall1995,
  langid = {english},
  title = {Dynamics of Learning and Recall at Excitatory Recurrent Synapses and Cholinergic Modulation in Rat Hippocampal Region {{CA3}}},
  volume = {15},
  issn = {0270-6474},
  abstract = {Hippocampal region CA3 contains strong recurrent excitation mediated by synapses of the longitudinal association fibers. These recurrent excitatory connections may play a dominant role in determining the information processing characteristics of this region. However, they result in feedback dynamics that may cause both runaway excitatory activity and runaway synaptic modification. Previous models of recurrent excitation have prevented unbounded activity using biologically unrealistic techniques. Here, the activation of feedback inhibition is shown to prevent unbounded activity, allowing stable activity states during recall and learning. In the model, cholinergic suppression of synaptic transmission at excitatory feedback synapses is shown to determine the extent to which activity depends upon new features of the afferent input versus components of previously stored representations. Experimental work in brain slice preparations of region CA3 demonstrates the cholinergic suppression of synaptic transmission in stratum radiatum, which contains synapses of the longitudinal association fibers.},
  issue = {7 Pt 2},
  journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  shortjournal = {J. Neurosci.},
  date = {1995-07},
  pages = {5249-5262},
  keywords = {Synapses,Animals,Synaptic Transmission,Mental Recall,Rats,Hippocampus,Models; Neurological,Learning,Rats; Sprague-Dawley,Parasympathetic Nervous System},
  author = {Hasselmo, M. E. and Schnell, E. and Barkai, E.},
  eprinttype = {pmid},
  eprint = {7623149},
  pmcid = {PMC6577857}
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  langid = {english},
  title = {Learning Representations by Back-Propagating Errors},
  volume = {323},
  issn = {1476-4687},
  url = {https://www.nature.com/articles/323533a0},
  doi = {10.1038/323533a0},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  number = {6088},
  journaltitle = {Nature},
  shortjournal = {Nature},
  urldate = {2019-11-25},
  date = {1986-10},
  pages = {533-536},
  author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  file = {/home/alec/Zotero/storage/H2PP9874/Rumelhart et al. - 1986 - Learning representations by back-propagating error.pdf;/home/alec/Zotero/storage/288I54UV/323533a0.html}
}

@article{izhikevichSimpleModelSpiking2003,
  langid = {english},
  title = {Simple Model of Spiking Neurons},
  volume = {14},
  issn = {1045-9227},
  doi = {10.1109/TNN.2003.820440},
  abstract = {A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.},
  number = {6},
  journaltitle = {IEEE transactions on neural networks},
  shortjournal = {IEEE Trans Neural Netw},
  date = {2003},
  pages = {1569-1572},
  author = {Izhikevich, E. M.},
  file = {/home/alec/Zotero/storage/XGXJFU7B/Izhikevich - 2003 - Simple model of spiking neurons.pdf},
  eprinttype = {pmid},
  eprint = {18244602}
}

@article{poiraziPyramidalNeuronTwolayer2003,
  langid = {english},
  title = {Pyramidal Neuron as Two-Layer Neural Network},
  volume = {37},
  issn = {0896-6273},
  doi = {10.1016/s0896-6273(03)00149-1},
  abstract = {The pyramidal neuron is the principal cell type in the mammalian forebrain, but its function remains poorly understood. Using a detailed compartmental model of a hippocampal CA1 pyramidal cell, we recorded responses to complex stimuli consisting of dozens of high-frequency activated synapses distributed throughout the apical dendrites. We found the cell's firing rate could be predicted by a simple formula that maps the physical components of the cell onto those of an abstract two-layer "neural network." In the first layer, synaptic inputs drive independent sigmoidal subunits corresponding to the cell's several dozen long, thin terminal dendrites. The subunit outputs are then summed within the main trunk and cell body prior to final thresholding. We conclude that insofar as the neural code is mediated by average firing rate, a two-layer neural network may provide a useful abstraction for the computing function of the individual pyramidal neuron.},
  number = {6},
  journaltitle = {Neuron},
  shortjournal = {Neuron},
  date = {2003-03-27},
  pages = {989-999},
  keywords = {Synapses,Biophysics,Electric Conductivity,Potassium Channels,Sodium Channels,Nerve Net,Calcium,Electrophysiology,Dendrites,Mathematics,Biophysical Phenomena,Models; Biological,Pyramidal Cells},
  author = {Poirazi, Panayiota and Brannon, Terrence and Mel, Bartlett W.},
  eprinttype = {pmid},
  eprint = {12670427}
}

@article{polskyComputationalSubunitsThin2004,
  langid = {english},
  title = {Computational Subunits in Thin Dendrites of Pyramidal Cells},
  volume = {7},
  issn = {1097-6256},
  doi = {10.1038/nn1253},
  abstract = {The thin basal and oblique dendrites of cortical pyramidal neurons receive most of the synaptic inputs from other cells, but their integrative properties remain uncertain. Previous studies have most often reported global linear or sublinear summation. An alternative view, supported by biophysical modeling studies, holds that thin dendrites provide a layer of independent computational 'subunits' that sigmoidally modulate their inputs prior to global summation. To distinguish these possibilities, we combined confocal imaging and dual-site focal synaptic stimulation of identified thin dendrites in rat neocortical pyramidal neurons. We found that nearby inputs on the same branch summed sigmoidally, whereas widely separated inputs or inputs to different branches summed linearly. This strong spatial compartmentalization effect is incompatible with a global summation rule and provides the first experimental support for a two-layer 'neural network' model of pyramidal neuron thin-branch integration. Our findings could have important implications for the computing and memory-related functions of cortical tissue.},
  number = {6},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat. Neurosci.},
  date = {2004-06},
  pages = {621-627},
  keywords = {Animals,Rats,Nerve Net,Dendrites,Excitatory Postsynaptic Potentials,Pyramidal Cells,Rats; Wistar,Neocortex},
  author = {Polsky, Alon and Mel, Bartlett W. and Schiller, Jackie},
  eprinttype = {pmid},
  eprint = {15156147}
}

@article{traubFastRhythmicBursting2003,
  langid = {english},
  title = {Fast Rhythmic Bursting Can Be Induced in Layer 2/3 Cortical Neurons by Enhancing Persistent {{Na}}+ Conductance or by Blocking {{BK}} Channels},
  volume = {89},
  issn = {0022-3077},
  doi = {10.1152/jn.00573.2002},
  abstract = {Fast rhythmic bursting (or "chattering") is a firing pattern exhibited by selected neocortical neurons in cats in vivo and in slices of adult ferret and cat brain. Fast rhythmic bursting (FRB) has been recorded in certain superficial and deep principal neurons and in aspiny presumed local circuit neurons; it can be evoked by depolarizing currents or by sensory stimulation and has been proposed to depend on a persistent g(Na) that causes spike depolarizing afterpotentials. We constructed a multicompartment 11-conductance model of a layer 2/3 pyramidal neuron, containing apical dendritic calcium-mediated electrogenesis; the model can switch between rhythmic spiking (RS) and FRB modes of firing, with various parameter changes. FRB in this model is favored by enhancing persistent g(Na) and also by measures that reduce [Ca(2+)](i) or that reduce the conductance of g(K(C)) (a fast voltage- and Ca(2+)-dependent conductance). Axonal excitability plays a critical role in generating fast bursts in the model. In vitro experiments in rat layer 2/3 neurons confirmed (as shown previously by others) that RS firing could be switched to fast rhythmic bursting, either by buffering [Ca(2+)](i) or by enhancing persistent g(Na). In addition, our experiments confirmed the model prediction that reducing g(KC) (with iberiotoxin) would favor FRB. During the bursts, fast prepotentials (spikelets) could occur that did not originate in apical dendrites and that appear to derive from the axon. We suggest that modulator-induced regulation of [Ca(2+)] dynamics or of BK channel conductance, for example via protein kinase A, could play a role in determining the firing pattern of neocortical neurons; specifically, such modulation could play a role in regulating whether neurons respond to strong stimulation with fast rhythmic bursts.},
  number = {2},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J. Neurophysiol.},
  date = {2003-02},
  pages = {909-921},
  keywords = {Animals,Action Potentials,Rats,Male,Models; Neurological,Sodium Channels,Periodicity,Cerebral Cortex,Calcium,Sodium,Axons,Organ Culture Techniques,Pyramidal Cells,Rats; Wistar,Large-Conductance Calcium-Activated Potassium Channels,Nitric Oxide Donors,Penicillamine,Potassium Channels; Calcium-Activated},
  author = {Traub, Roger D. and Buhl, Eberhard H. and Gloveli, Tengis and Whittington, Miles A.},
  file = {/home/alec/Zotero/storage/UBC35TY6/Traub et al. - 2003 - Fast rhythmic bursting can be induced in layer 23.pdf},
  eprinttype = {pmid},
  eprint = {12574468}
}

@article{traubSinglecolumnThalamocorticalNetwork2005,
  langid = {english},
  title = {Single-Column Thalamocortical Network Model Exhibiting Gamma Oscillations, Sleep Spindles, and Epileptogenic Bursts},
  volume = {93},
  issn = {0022-3077},
  doi = {10.1152/jn.00983.2004},
  abstract = {To better understand population phenomena in thalamocortical neuronal ensembles, we have constructed a preliminary network model with 3,560 multicompartment neurons (containing soma, branching dendrites, and a portion of axon). Types of neurons included superficial pyramids (with regular spiking [RS] and fast rhythmic bursting [FRB] firing behaviors); RS spiny stellates; fast spiking (FS) interneurons, with basket-type and axoaxonic types of connectivity, and located in superficial and deep cortical layers; low threshold spiking (LTS) interneurons, which contacted principal cell dendrites; deep pyramids, which could have RS or intrinsic bursting (IB) firing behaviors, and endowed either with nontufted apical dendrites or with long tufted apical dendrites; thalamocortical relay (TCR) cells; and nucleus reticularis (nRT) cells. To the extent possible, both electrophysiology and synaptic connectivity were based on published data, although many arbitrary choices were necessary. In addition to synaptic connectivity (by AMPA/kainate, NMDA, and GABA(A) receptors), we also included electrical coupling between dendrites of interneurons, nRT cells, and TCR cells, and--in various combinations--electrical coupling between the proximal axons of certain cortical principal neurons. Our network model replicates several observed population phenomena, including 1) persistent gamma oscillations; 2) thalamocortical sleep spindles; 3) series of synchronized population bursts, resembling electrographic seizures; 4) isolated double population bursts with superimposed very fast oscillations ({$>$}100 Hz, "VFO"); 5) spike-wave, polyspike-wave, and fast runs (about 10 Hz). We show that epileptiform bursts, including double and multiple bursts, containing VFO occur in rat auditory cortex in vitro, in the presence of kainate, when both GABA(A) and GABA(B) receptors are blocked. Electrical coupling between axons appears necessary (as reported previously) for persistent gamma and additionally plays a role in the detailed shaping of epileptogenic events. The degree of recurrent synaptic excitation between spiny stellate cells, and their tendency to fire throughout multiple bursts, also appears critical in shaping epileptogenic events.},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J. Neurophysiol.},
  date = {2005-04},
  pages = {2194-2232},
  keywords = {Animals,Action Potentials,Rats,Thalamus,Male,Models; Neurological,Nerve Net,Cerebral Cortex,Biological Clocks,Rats; Sprague-Dawley,Rats; Wistar,Epilepsy,Sleep},
  author = {Traub, Roger D. and Contreras, Diego and Cunningham, Mark O. and Murray, Hilary and LeBeau, Fiona E. N. and Roopun, Anita and Bibbig, Andrea and Wilent, W. Bryan and Higley, Michael J. and Whittington, Miles A.},
  file = {/home/alec/Zotero/storage/XZSC7YL3/Traub et al. - 2005 - Single-column thalamocortical network model exhibi.pdf},
  eprinttype = {pmid},
  eprint = {15525801}
}

@article{alvarezLearningNumberNeurons2018,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1611.06321},
  primaryClass = {cs},
  title = {Learning the {{Number}} of {{Neurons}} in {{Deep Networks}}},
  url = {http://arxiv.org/abs/1611.06321},
  abstract = {Nowadays, the number of layers and of neurons in each layer of a deep network are typically set manually. While very deep and wide networks have proven effective in general, they come at a high memory and computation cost, thus making them impractical for constrained platforms. These networks, however, are known to have many redundant parameters, and could thus, in principle, be replaced by more compact architectures. In this paper, we introduce an approach to automatically determining the number of neurons in each layer of a deep network during learning. To this end, we propose to make use of structured sparsity during learning. More precisely, we use a group sparsity regularizer on the parameters of the network, where each group is defined to act on a single neuron. Starting from an overcomplete network, we show that our approach can reduce the number of parameters by up to 80\textbackslash\% while retaining or even improving the network accuracy.},
  urldate = {2019-11-27},
  date = {2018-10-11},
  keywords = {Computer Science - Machine Learning,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Neural and Evolutionary Computing},
  author = {Alvarez, Jose M. and Salzmann, Mathieu},
  file = {/home/alec/Zotero/storage/UPFEL75V/Alvarez and Salzmann - 2018 - Learning the Number of Neurons in Deep Networks.pdf;/home/alec/Zotero/storage/VFWP9Y5G/1611.html}
}

@article{canzianiAnalysisDeepNeural2017,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.07678},
  primaryClass = {cs},
  title = {An {{Analysis}} of {{Deep Neural Network Models}} for {{Practical Applications}}},
  url = {http://arxiv.org/abs/1605.07678},
  abstract = {Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.},
  urldate = {2019-11-26},
  date = {2017-04-14},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Canziani, Alfredo and Paszke, Adam and Culurciello, Eugenio},
  file = {/home/alec/Zotero/storage/52AYWG4U/Canziani et al. - 2017 - An Analysis of Deep Neural Network Models for Prac.pdf;/home/alec/Zotero/storage/A92L96YD/1605.html}
}

@article{heDeepResidualLearning2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1512.03385},
  primaryClass = {cs},
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  url = {http://arxiv.org/abs/1512.03385},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  urldate = {2019-11-26},
  date = {2015-12-10},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  file = {/home/alec/Zotero/storage/E6SDIDLX/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf;/home/alec/Zotero/storage/Y846DGIZ/1512.html}
}

@article{simonyanVeryDeepConvolutional2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1409.1556},
  primaryClass = {cs},
  title = {Very {{Deep Convolutional Networks}} for {{Large}}-{{Scale Image Recognition}}},
  url = {http://arxiv.org/abs/1409.1556},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  urldate = {2019-11-26},
  date = {2015-04-10},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Simonyan, Karen and Zisserman, Andrew},
  file = {/home/alec/Zotero/storage/62P8ZU4S/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf;/home/alec/Zotero/storage/9HN3GK9P/1409.html}
}

@article{krizhevskyImageNetClassificationDeep2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  volume = {60},
  issn = {0001-0782},
  url = {http://dl.acm.org/citation.cfm?id=3098997.3065386},
  doi = {10.1145/3065386},
  number = {6},
  journaltitle = {Communications of the ACM},
  urldate = {2019-11-26},
  date = {2017-05-24},
  pages = {84-90},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  file = {/home/alec/Zotero/storage/FMEMB5JU/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf}
}

@article{schmidhuberDeepLearningNeural2015a,
  title = {Deep {{Learning}} in {{Neural Networks}}: {{An Overview}}},
  volume = {61},
  issn = {08936080},
  url = {http://arxiv.org/abs/1404.7828},
  doi = {10.1016/j.neunet.2014.09.003},
  shorttitle = {Deep {{Learning}} in {{Neural Networks}}},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  urldate = {2019-11-26},
  date = {2015-01},
  pages = {85-117},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  author = {Schmidhuber, Juergen},
  file = {/home/alec/Zotero/storage/KQ2C9WDK/Schmidhuber - 2015 - Deep Learning in Neural Networks An Overview.pdf;/home/alec/Zotero/storage/UA32GKS8/Schmidhuber - 2015 - Deep Learning in Neural Networks An Overview.pdf;/home/alec/Zotero/storage/3W3HP6UV/1404.html;/home/alec/Zotero/storage/5U4Y8M4I/1404.html},
  ids = {schmidhuberDeepLearningNeural2015},
  eprinttype = {arxiv},
  eprint = {[object Object]}
}

@article{wangGammaOscillationSynaptic1996,
  langid = {english},
  title = {Gamma {{Oscillation}} by {{Synaptic Inhibition}} in a {{Hippocampal Interneuronal Network Model}}},
  volume = {16},
  issn = {0270-6474, 1529-2401},
  url = {https://www.jneurosci.org/content/16/20/6402},
  doi = {10.1523/JNEUROSCI.16-20-06402.1996},
  abstract = {Fast neuronal oscillations (gamma, 20–80 Hz) have been observed in the neocortex and hippocampus during behavioral arousal. Using computer simulations, we investigated the hypothesis that such rhythmic activity can emerge in a random network of interconnected GABAergic fast-spiking interneurons. Specific conditions for the population synchronization, on properties of single cells and the circuit, were identified. These include the following: (1) that the amplitude of spike afterhyperpolarization be above the GABAA synaptic reversal potential; (2) that the ratio between the synaptic decay time constant and the oscillation period be sufficiently large; (3) that the effects of heterogeneities be modest because of a steep frequency–current relationship of fast-spiking neurons. Furthermore, using a population coherence measure, based on coincident firings of neural pairs, it is demonstrated that large-scale network synchronization requires a critical (minimal) average number of synaptic contacts per cell, which is not sensitive to the network size.
By changing the GABAA synaptic maximal conductance, synaptic decay time constant, or the mean external excitatory drive to the network, the neuronal firing frequencies were gradually and monotonically varied. By contrast, the network synchronization was found to be high only within a frequency band coinciding with the gamma (20–80 Hz) range. We conclude that the GABAA synaptic transmission provides a suitable mechanism for synchronized gamma oscillations in a sparsely connected network of fast-spiking interneurons. In turn, the interneuronal network can presumably maintain subthreshold oscillations in principal cell populations and serve to synchronize discharges of spatially distributed neurons.},
  number = {20},
  journaltitle = {Journal of Neuroscience},
  shortjournal = {J. Neurosci.},
  urldate = {2019-11-26},
  date = {1996-10-15},
  pages = {6402-6413},
  keywords = {hippocampus,interneurons,computer model,GABAA,gamma rhythm,synchronization},
  author = {Wang, Xiao-Jing and Buzsáki, György},
  file = {/home/alec/Zotero/storage/Q7BHA8QQ/Wang and Buzsáki - 1996 - Gamma Oscillation by Synaptic Inhibition in a Hipp.pdf;/home/alec/Zotero/storage/IFIMQHV3/6402.html},
  eprinttype = {pmid},
  eprint = {8815919}
}

@article{bartosFastSynapticInhibition2002,
  langid = {english},
  title = {Fast Synaptic Inhibition Promotes Synchronized Gamma Oscillations in Hippocampal Interneuron Networks},
  volume = {99},
  issn = {0027-8424, 1091-6490},
  url = {https://www.pnas.org/content/99/20/13222},
  doi = {10.1073/pnas.192233099},
  abstract = {Networks of GABAergic interneurons are of critical importance for the generation of gamma frequency oscillations in the brain. To examine the underlying synaptic mechanisms, we made paired recordings from “basket cells” (BCs) in different subfields of hippocampal slices, using transgenic mice that express enhanced green fluorescent protein (EGFP) under the control of the parvalbumin promoter. Unitary inhibitory postsynaptic currents (IPSCs) showed large amplitude and fast time course with mean amplitude-weighted decay time constants of 2.5, 1.2, and 1.8 ms in the dentate gyrus, and the cornu ammonis area 3 (CA3) and 1 (CA1), respectively (33–34°C). The decay of unitary IPSCs at BC–BC synapses was significantly faster than that at BC–principal cell synapses, indicating target cell-specific differences in IPSC kinetics. In addition, electrical coupling was found in a subset of BC–BC pairs. To examine whether an interneuron network with fast inhibitory synapses can act as a gamma frequency oscillator, we developed an interneuron network model based on experimentally determined properties. In comparison to previous interneuron network models, our model was able to generate oscillatory activity with higher coherence over a broad range of frequencies (20–110 Hz). In this model, high coherence and flexibility in frequency control emerge from the combination of synaptic properties, network structure, and electrical coupling.},
  number = {20},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  urldate = {2019-11-26},
  date = {2002-10-01},
  pages = {13222-13227},
  author = {Bartos, Marlene and Vida, Imre and Frotscher, Michael and Meyer, Axel and Monyer, Hannah and Geiger, Jörg R. P. and Jonas, Peter},
  file = {/home/alec/Zotero/storage/GIBAMX28/Bartos et al. - 2002 - Fast synaptic inhibition promotes synchronized gam.pdf;/home/alec/Zotero/storage/CZW2IQ7X/13222.html},
  eprinttype = {pmid},
  eprint = {12235359}
}

@article{hillModelIntersegmentalCoordination2002a,
  langid = {english},
  title = {Model of Intersegmental Coordination in the Leech Heartbeat Neuronal Network},
  volume = {87},
  issn = {0022-3077},
  doi = {10.1152/jn.00337.2001},
  abstract = {We have created a computational model of the timing network that paces the heartbeat of the medicinal leech, Hirudo medicinalis. The rhythmic activity of this network originates from two segmental oscillators located in the third and fourth midbody ganglia. In the intact nerve cord, these segmental oscillators are mutually entrained to the same cycle period. Although experiments have shown that the segmental oscillators are coupled by inhibitory coordinating interneurons, the underlying mechanisms of intersegmental coordination have not yet been elucidated. To help understand this coordination, we have created a simple computational model with two variants: symmetric and asymmetric. In the symmetric model, neurons within each segmental oscillator called oscillator interneurons, inhibit the coordinating interneurons. In contrast, in the asymmetric model only the oscillator interneurons of one segmental oscillator inhibit the coordinating interneurons. In the symmetric model, when two segmental oscillators with different inherent periods are coupled, the faster one leads in phase, and the period of the coupled system is equal to the period of the faster oscillator. This behavior arises because, during each oscillation cycle, the oscillator interneurons of the faster segmental oscillator begin to burst before those of the slower oscillator, thereby terminating spike activity in the coordinating interneurons. Thus there is a brief period of time in each cycle when the oscillator interneurons of the slower segmental oscillator are relieved of inhibition from the coordinating interneurons. This "removal of synaptic inhibition" allows, within certain limits, the slower segmental oscillator to be sped to the period of the faster one. Thus the symmetric model demonstrates a plausible biophysical mechanism by which one segmental oscillator can entrain the other. In general the asymmetric model, in which only one segmental oscillator has the ability to inhibit the coordinating interneurons, behaves similarly, except only one segmental oscillator can control the period of the system. In addition, we simulated physiological experiments in which a "driving" stimulus, consisting of alternating positive and negative current steps, was used to control a single oscillator interneuron and thereby entrain the activity of the entire timing network.},
  number = {3},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {J. Neurophysiol.},
  date = {2002-03},
  pages = {1586-1602},
  keywords = {Animals,Action Potentials,Interneurons,Ganglia; Invertebrate,Periodicity,Neural Networks (Computer),Nervous System,Neural Inhibition,Heart,Heart Rate,Leeches},
  author = {Hill, Andrew A. V. and Masino, Mark A. and Calabrese, Ronald L.},
  file = {/home/alec/Zotero/storage/RSKRQQHZ/Hill et al. - 2002 - Model of intersegmental coordination in the leech .pdf},
  eprinttype = {pmid},
  eprint = {11877528}
}

@article{lyttonDynamicInteractionsDetermine1997,
  title = {Dynamic {{Interactions Determine Partial Thalamic Quiescence}} in a {{Computer Network Model}} of {{Spike}}-and-{{Wave Seizures}}},
  volume = {77},
  issn = {0022-3077},
  url = {https://www.physiology.org/doi/full/10.1152/jn.1997.77.4.1679},
  doi = {10.1152/jn.1997.77.4.1679},
  abstract = {Lytton, William W., Diego Contreras, Alain Destexhe, and Mircea Steriade. Dynamic interactions determine partial thalamic quiescence in a computer network model of spike-and-wave seizures. J. Neurophysiol. 77: 1679–1696, 1997. In vivo intracellular recording from cat thalamus and cortex was performed during spontaneous spike-wave seizures characterized by synchronously firing cortical neurons correlated with the electroencephalogram. During these seizures, thalamic reticular (RE) neurons discharged with long spike bursts riding on a depolarization, whereas thalamocortical (TC) neurons were either entrained into the seizures (40\%) or were quiescent (60\%). During quiescence, TC neurons showed phasic inhibitory postsynaptic potentials (IPSPs) that coincided with paroxysmal depolarizing shifts in the simultaneously recorded cortical neuron. Computer simulations of a reciprocally connected TC-RE pair showed two major modes of TC-RE interaction. In one mode, a mutual oscillation involved direct TC neuron excitation of the RE neuron leading to a burst that fed back an IPSP into the TC neuron, producing a low-threshold spike. In the other, quiescent mode, the TC neuron was subject to stronger coalescing IPSPs. Simulated cortical stimulation could trigger a transition between the two modes. This transition could go in either direction and was dependent on the precise timing of the input. The transition did not always follow the stimulation immediately. A larger, multicolumnar simulation was set up to assess the role of the TC-RE pair in the context of extensive divergence and convergence. The amount of TC neuron spiking generally correlated with the strength of total inhibitory input, but large variations in the amount of spiking could be seen. Evidence for mutual oscillation could be demonstrated by comparing TC neuron firing with that in reciprocally connected RE neurons. An additional mechanism for TC neuron quiescence was assessed with the use of a cooperative model of γ-aminobutyric acid-B (GABAB)-mediated responses. With this model, RE neurons receiving repeated strong excitatory input produced TC neuron quiescence due to burst-duration-associated augmentation of GABAB current. We predict the existence of spatial inhomogeneity in apparently generalized spike-wave seizures, involving a center-surround pattern. In the center, intense cortical and RE neuron activity would be associated with TC neuron quiescence. In the surround, less intense hyperpolarization of TC neurons would allow low-threshold spikes to occur. This surround, an “epileptic penumbra,” would be the forefront of the expanding epileptic wave during the process of initial seizure generalization. Therapeutically, we would then predict that agents that reduce TC neuron activity would have a greater effect on seizure onset than on ongoing spike-wave seizures or other thalamic oscillations.},
  number = {4},
  journaltitle = {Journal of Neurophysiology},
  shortjournal = {Journal of Neurophysiology},
  urldate = {2019-11-26},
  date = {1997-04-01},
  pages = {1679-1696},
  author = {Lytton, William W. and Contreras, Diego and Destexhe, Alain and Steriade, Mircea},
  file = {/home/alec/Zotero/storage/CYCZUVJB/Lytton et al. - 1997 - Dynamic Interactions Determine Partial Thalamic Qu.pdf;/home/alec/Zotero/storage/DNEUZ7MQ/jn.1997.77.4.html}
}

@article{nadimFrequencyRegulationSlow1998a,
  langid = {english},
  title = {Frequency Regulation of a Slow Rhythm by a Fast Periodic Input},
  volume = {18},
  issn = {0270-6474},
  abstract = {Many nervous systems contain rhythmically active subnetworks that interact despite oscillating at widely different frequencies. The stomatogastric nervous system of the crab Cancer borealis produces a rapid pyloric rhythm and a considerably slower gastric mill rhythm. We construct and analyze a conductance-based compartmental model to explore the activation of the gastric mill rhythm by the modulatory commissural neuron 1 (MCN1). This model demonstrates that the period of the MCN1-activated gastric mill rhythm, which was thought to be determined entirely by the interaction of neurons in the gastric mill network, can be strongly influenced by inhibitory synaptic input from the pacemaker neuron of the fast pyloric rhythm, the anterior burster (AB) neuron. Surprisingly, the change of the gastric mill period produced by the pyloric input to the gastric mill system can be many times larger than the period of the pyloric rhythm itself. This model illustrates several mechanisms by which a fast oscillatory neuron may control the frequency of a much slower oscillatory network. These findings suggest that it is possible to modify the slow rhythm either by direct modulation or indirectly by modulating the faster rhythm.},
  number = {13},
  journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  shortjournal = {J. Neurosci.},
  date = {1998-07-01},
  pages = {5053-5067},
  keywords = {Neurons,Animals,Action Potentials,Models; Neurological,Ganglia; Invertebrate,Brachyura,Nervous System Physiological Phenomena,Periodicity,Electrophysiology,Pylorus,Time Factors},
  author = {Nadim, F. and Manor, Y. and Nusbaum, M. P. and Marder, E.},
  eprinttype = {pmid},
  eprint = {9634571},
  pmcid = {PMC6792559}
}

@article{potjansCelltypeSpecificCortical2014,
  langid = {english},
  title = {The Cell-Type Specific Cortical Microcircuit: Relating Structure and Activity in a Full-Scale Spiking Network Model},
  volume = {24},
  issn = {1460-2199},
  doi = {10.1093/cercor/bhs358},
  shorttitle = {The Cell-Type Specific Cortical Microcircuit},
  abstract = {In the past decade, the cell-type specific connectivity and activity of local cortical networks have been characterized experimentally to some detail. In parallel, modeling has been established as a tool to relate network structure to activity dynamics. While available comprehensive connectivity maps ( Thomson, West, et al. 2002; Binzegger et al. 2004) have been used in various computational studies, prominent features of the simulated activity such as the spontaneous firing rates do not match the experimental findings. Here, we analyze the properties of these maps to compile an integrated connectivity map, which additionally incorporates insights on the specific selection of target types. Based on this integrated map, we build a full-scale spiking network model of the local cortical microcircuit. The simulated spontaneous activity is asynchronous irregular and cell-type specific firing rates are in agreement with in vivo recordings in awake animals, including the low rate of layer 2/3 excitatory cells. The interplay of excitation and inhibition captures the flow of activity through cortical layers after transient thalamic stimulation. In conclusion, the integration of a large body of the available connectivity data enables us to expose the dynamical consequences of the cortical microcircuitry.},
  number = {3},
  journaltitle = {Cerebral Cortex (New York, N.Y.: 1991)},
  shortjournal = {Cereb. Cortex},
  date = {2014-03},
  pages = {785-806},
  keywords = {Neurons,Action Potentials,Humans,Neural Pathways,Models; Neurological,Nerve Net,Cerebral Cortex,Neural Networks (Computer),Neural Inhibition,Computer Simulation,large-scale models,connectivity maps,cortical microcircuit,layered network,specificity of connections},
  author = {Potjans, Tobias C. and Diesmann, Markus},
  file = {/home/alec/Zotero/storage/VF7TV46T/Potjans and Diesmann - 2014 - The cell-type specific cortical microcircuit rela.pdf},
  eprinttype = {pmid},
  eprint = {23203991},
  pmcid = {PMC3920768}
}

@article{sadehAssessingRoleInhibition2017,
  langid = {english},
  title = {Assessing the {{Role}} of {{Inhibition}} in {{Stabilizing Neocortical Networks Requires Large}}-{{Scale Perturbation}} of the {{Inhibitory Population}}},
  volume = {37},
  issn = {1529-2401},
  doi = {10.1523/JNEUROSCI.0963-17.2017},
  abstract = {Neurons within cortical microcircuits are interconnected with recurrent excitatory synaptic connections that are thought to amplify signals (Douglas and Martin, 2007), form selective subnetworks (Ko et al., 2011), and aid feature discrimination. Strong inhibition (Haider et al., 2013) counterbalances excitation, enabling sensory features to be sharpened and represented by sparse codes (Willmore et al., 2011). This balance between excitation and inhibition makes it difficult to assess the strength, or gain, of recurrent excitatory connections within cortical networks, which is key to understanding their operational regime and the computations that they perform. Networks that combine an unstable high-gain excitatory population with stabilizing inhibitory feedback are known as inhibition-stabilized networks (ISNs) (Tsodyks et al., 1997). Theoretical studies using reduced network models predict that ISNs produce paradoxical responses to perturbation, but experimental perturbations failed to find evidence for ISNs in cortex (Atallah et al., 2012). Here, we reexamined this question by investigating how cortical network models consisting of many neurons behave after perturbations and found that results obtained from reduced network models fail to predict responses to perturbations in more realistic networks. Our models predict that a large proportion of the inhibitory network must be perturbed to reliably detect an ISN regime robustly in cortex. We propose that wide-field optogenetic suppression of inhibition under promoters targeting a large fraction of inhibitory neurons may provide a perturbation of sufficient strength to reveal the operating regime of cortex. Our results suggest that detailed computational models of optogenetic perturbations are necessary to interpret the results of experimental paradigms.SIGNIFICANCE STATEMENT Many useful computational mechanisms proposed for cortex require local excitatory recurrence to be very strong, such that local inhibitory feedback is necessary to avoid epileptiform runaway activity (an "inhibition-stabilized network" or "ISN" regime). However, recent experimental results suggest that this regime may not exist in cortex. We simulated activity perturbations in cortical networks of increasing realism and found that, to detect ISN-like properties in cortex, large proportions of the inhibitory population must be perturbed. Current experimental methods for inhibitory perturbation are unlikely to satisfy this requirement, implying that existing experimental observations are inconclusive about the computational regime of cortex. Our results suggest that new experimental designs targeting a majority of inhibitory neurons may be able to resolve this question.},
  number = {49},
  journaltitle = {The Journal of Neuroscience: The Official Journal of the Society for Neuroscience},
  shortjournal = {J. Neurosci.},
  date = {2017-06-12},
  pages = {12050-12067},
  keywords = {Animals,Action Potentials,Humans,Nerve Net,Neural Inhibition,Neocortex,computational model,cortical computation,inhibitory stabilization,optogenetics,recurrent excitation},
  author = {Sadeh, Sadra and Silver, R. Angus and Mrsic-Flogel, Thomas D. and Muir, Dylan Richard},
  file = {/home/alec/Zotero/storage/9925C2BK/Sadeh et al. - 2017 - Assessing the Role of Inhibition in Stabilizing Ne.pdf},
  eprinttype = {pmid},
  eprint = {29074575},
  pmcid = {PMC5719979}
}


